{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Code_Phase-5_Group-10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4hokpodbuaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from sklearn.metrics import classification_report,confusion_matrix, roc_curve, roc_auc_score, auc, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
        "import seaborn as sns\n",
        "from collections import defaultdict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9K-vVhUb3E2",
        "colab_type": "code",
        "outputId": "5774ebe9-7dc0-45ea-d5ba-02cce35c71be",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "names = ['existingchecking', 'duration', 'credithistory', 'purpose', 'creditamount', \n",
        "         'savings', 'employmentsince', 'installmentrate', 'statussex', 'otherdebtors', \n",
        "         'residencesince', 'property', 'age', 'otherinstallmentplans', 'housing', \n",
        "         'existingcredits', 'job', 'peopleliable', 'telephone', 'foreignworker', 'classification']\n",
        "\n",
        "from google.colab import files\n",
        "import io\n",
        "uploaded = files.upload()\n",
        "data = pd.read_csv(io.BytesIO(uploaded['german.data']),names = names, delimiter=' ')\n",
        "\n",
        "print(data.shape)\n",
        "print (data.columns)\n",
        "data.head(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ebe303c8-c07c-4432-a5e6-47c972c544d5\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-ebe303c8-c07c-4432-a5e6-47c972c544d5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving german.data to german.data\n",
            "(1000, 21)\n",
            "Index(['existingchecking', 'duration', 'credithistory', 'purpose',\n",
            "       'creditamount', 'savings', 'employmentsince', 'installmentrate',\n",
            "       'statussex', 'otherdebtors', 'residencesince', 'property', 'age',\n",
            "       'otherinstallmentplans', 'housing', 'existingcredits', 'job',\n",
            "       'peopleliable', 'telephone', 'foreignworker', 'classification'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>existingchecking</th>\n",
              "      <th>duration</th>\n",
              "      <th>credithistory</th>\n",
              "      <th>purpose</th>\n",
              "      <th>creditamount</th>\n",
              "      <th>savings</th>\n",
              "      <th>employmentsince</th>\n",
              "      <th>installmentrate</th>\n",
              "      <th>statussex</th>\n",
              "      <th>otherdebtors</th>\n",
              "      <th>residencesince</th>\n",
              "      <th>property</th>\n",
              "      <th>age</th>\n",
              "      <th>otherinstallmentplans</th>\n",
              "      <th>housing</th>\n",
              "      <th>existingcredits</th>\n",
              "      <th>job</th>\n",
              "      <th>peopleliable</th>\n",
              "      <th>telephone</th>\n",
              "      <th>foreignworker</th>\n",
              "      <th>classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A11</td>\n",
              "      <td>6</td>\n",
              "      <td>A34</td>\n",
              "      <td>A43</td>\n",
              "      <td>1169</td>\n",
              "      <td>A65</td>\n",
              "      <td>A75</td>\n",
              "      <td>4</td>\n",
              "      <td>A93</td>\n",
              "      <td>A101</td>\n",
              "      <td>4</td>\n",
              "      <td>A121</td>\n",
              "      <td>67</td>\n",
              "      <td>A143</td>\n",
              "      <td>A152</td>\n",
              "      <td>2</td>\n",
              "      <td>A173</td>\n",
              "      <td>1</td>\n",
              "      <td>A192</td>\n",
              "      <td>A201</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A12</td>\n",
              "      <td>48</td>\n",
              "      <td>A32</td>\n",
              "      <td>A43</td>\n",
              "      <td>5951</td>\n",
              "      <td>A61</td>\n",
              "      <td>A73</td>\n",
              "      <td>2</td>\n",
              "      <td>A92</td>\n",
              "      <td>A101</td>\n",
              "      <td>2</td>\n",
              "      <td>A121</td>\n",
              "      <td>22</td>\n",
              "      <td>A143</td>\n",
              "      <td>A152</td>\n",
              "      <td>1</td>\n",
              "      <td>A173</td>\n",
              "      <td>1</td>\n",
              "      <td>A191</td>\n",
              "      <td>A201</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A14</td>\n",
              "      <td>12</td>\n",
              "      <td>A34</td>\n",
              "      <td>A46</td>\n",
              "      <td>2096</td>\n",
              "      <td>A61</td>\n",
              "      <td>A74</td>\n",
              "      <td>2</td>\n",
              "      <td>A93</td>\n",
              "      <td>A101</td>\n",
              "      <td>3</td>\n",
              "      <td>A121</td>\n",
              "      <td>49</td>\n",
              "      <td>A143</td>\n",
              "      <td>A152</td>\n",
              "      <td>1</td>\n",
              "      <td>A172</td>\n",
              "      <td>2</td>\n",
              "      <td>A191</td>\n",
              "      <td>A201</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A11</td>\n",
              "      <td>42</td>\n",
              "      <td>A32</td>\n",
              "      <td>A42</td>\n",
              "      <td>7882</td>\n",
              "      <td>A61</td>\n",
              "      <td>A74</td>\n",
              "      <td>2</td>\n",
              "      <td>A93</td>\n",
              "      <td>A103</td>\n",
              "      <td>4</td>\n",
              "      <td>A122</td>\n",
              "      <td>45</td>\n",
              "      <td>A143</td>\n",
              "      <td>A153</td>\n",
              "      <td>1</td>\n",
              "      <td>A173</td>\n",
              "      <td>2</td>\n",
              "      <td>A191</td>\n",
              "      <td>A201</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A11</td>\n",
              "      <td>24</td>\n",
              "      <td>A33</td>\n",
              "      <td>A40</td>\n",
              "      <td>4870</td>\n",
              "      <td>A61</td>\n",
              "      <td>A73</td>\n",
              "      <td>3</td>\n",
              "      <td>A93</td>\n",
              "      <td>A101</td>\n",
              "      <td>4</td>\n",
              "      <td>A124</td>\n",
              "      <td>53</td>\n",
              "      <td>A143</td>\n",
              "      <td>A153</td>\n",
              "      <td>2</td>\n",
              "      <td>A173</td>\n",
              "      <td>2</td>\n",
              "      <td>A191</td>\n",
              "      <td>A201</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>A14</td>\n",
              "      <td>36</td>\n",
              "      <td>A32</td>\n",
              "      <td>A46</td>\n",
              "      <td>9055</td>\n",
              "      <td>A65</td>\n",
              "      <td>A73</td>\n",
              "      <td>2</td>\n",
              "      <td>A93</td>\n",
              "      <td>A101</td>\n",
              "      <td>4</td>\n",
              "      <td>A124</td>\n",
              "      <td>35</td>\n",
              "      <td>A143</td>\n",
              "      <td>A153</td>\n",
              "      <td>1</td>\n",
              "      <td>A172</td>\n",
              "      <td>2</td>\n",
              "      <td>A192</td>\n",
              "      <td>A201</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>A14</td>\n",
              "      <td>24</td>\n",
              "      <td>A32</td>\n",
              "      <td>A42</td>\n",
              "      <td>2835</td>\n",
              "      <td>A63</td>\n",
              "      <td>A75</td>\n",
              "      <td>3</td>\n",
              "      <td>A93</td>\n",
              "      <td>A101</td>\n",
              "      <td>4</td>\n",
              "      <td>A122</td>\n",
              "      <td>53</td>\n",
              "      <td>A143</td>\n",
              "      <td>A152</td>\n",
              "      <td>1</td>\n",
              "      <td>A173</td>\n",
              "      <td>1</td>\n",
              "      <td>A191</td>\n",
              "      <td>A201</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>A12</td>\n",
              "      <td>36</td>\n",
              "      <td>A32</td>\n",
              "      <td>A41</td>\n",
              "      <td>6948</td>\n",
              "      <td>A61</td>\n",
              "      <td>A73</td>\n",
              "      <td>2</td>\n",
              "      <td>A93</td>\n",
              "      <td>A101</td>\n",
              "      <td>2</td>\n",
              "      <td>A123</td>\n",
              "      <td>35</td>\n",
              "      <td>A143</td>\n",
              "      <td>A151</td>\n",
              "      <td>1</td>\n",
              "      <td>A174</td>\n",
              "      <td>1</td>\n",
              "      <td>A192</td>\n",
              "      <td>A201</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>A14</td>\n",
              "      <td>12</td>\n",
              "      <td>A32</td>\n",
              "      <td>A43</td>\n",
              "      <td>3059</td>\n",
              "      <td>A64</td>\n",
              "      <td>A74</td>\n",
              "      <td>2</td>\n",
              "      <td>A91</td>\n",
              "      <td>A101</td>\n",
              "      <td>4</td>\n",
              "      <td>A121</td>\n",
              "      <td>61</td>\n",
              "      <td>A143</td>\n",
              "      <td>A152</td>\n",
              "      <td>1</td>\n",
              "      <td>A172</td>\n",
              "      <td>1</td>\n",
              "      <td>A191</td>\n",
              "      <td>A201</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>A12</td>\n",
              "      <td>30</td>\n",
              "      <td>A34</td>\n",
              "      <td>A40</td>\n",
              "      <td>5234</td>\n",
              "      <td>A61</td>\n",
              "      <td>A71</td>\n",
              "      <td>4</td>\n",
              "      <td>A94</td>\n",
              "      <td>A101</td>\n",
              "      <td>2</td>\n",
              "      <td>A123</td>\n",
              "      <td>28</td>\n",
              "      <td>A143</td>\n",
              "      <td>A152</td>\n",
              "      <td>2</td>\n",
              "      <td>A174</td>\n",
              "      <td>1</td>\n",
              "      <td>A191</td>\n",
              "      <td>A201</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  existingchecking  duration  ... foreignworker classification\n",
              "0              A11         6  ...          A201              1\n",
              "1              A12        48  ...          A201              2\n",
              "2              A14        12  ...          A201              1\n",
              "3              A11        42  ...          A201              1\n",
              "4              A11        24  ...          A201              2\n",
              "5              A14        36  ...          A201              1\n",
              "6              A14        24  ...          A201              1\n",
              "7              A12        36  ...          A201              1\n",
              "8              A14        12  ...          A201              1\n",
              "9              A12        30  ...          A201              2\n",
              "\n",
              "[10 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7KflQ65c1wN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Binarize the y output for easier use of e.g. ROC curves -> 0 = 'bad' credit; 1 = 'good' credit\n",
        "data.classification.replace([1,2], [1,0], inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDI9T6guc7c5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#numerical variables labels\n",
        "numvars = ['creditamount', 'duration', 'installmentrate', 'residencesince', 'age', \n",
        "           'existingcredits', 'peopleliable', 'classification']\n",
        "\n",
        "# Standardization\n",
        "numdata_std = pd.DataFrame(StandardScaler().fit_transform(data[numvars].drop(['classification'], axis=1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbhBVrz9c9zz",
        "colab_type": "code",
        "outputId": "3e507230-b726-4534-9c4c-bac0d872c567",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "#categorical variables labels\n",
        "catvars = ['existingchecking', 'credithistory', 'purpose', 'savings', 'employmentsince',\n",
        "           'statussex', 'otherdebtors', 'property', 'otherinstallmentplans', 'housing', 'job', \n",
        "           'telephone', 'foreignworker']\n",
        "\n",
        "d = defaultdict(LabelEncoder)\n",
        "\n",
        "# Encoding the variable\n",
        "lecatdata = data[catvars].apply(lambda x: d[x.name].fit_transform(x))\n",
        "\n",
        "# print transformations\n",
        "for x in range(len(catvars)):\n",
        "    print(catvars[x],\": \", data[catvars[x]].unique())\n",
        "    print(catvars[x],\": \", lecatdata[catvars[x]].unique())\n",
        "\n",
        "#One hot encoding, create dummy variables for every category of every categorical variable\n",
        "dummyvars = pd.get_dummies(data[catvars])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "existingchecking :  ['A11' 'A12' 'A14' 'A13']\n",
            "existingchecking :  [0 1 3 2]\n",
            "credithistory :  ['A34' 'A32' 'A33' 'A30' 'A31']\n",
            "credithistory :  [4 2 3 0 1]\n",
            "purpose :  ['A43' 'A46' 'A42' 'A40' 'A41' 'A49' 'A44' 'A45' 'A410' 'A48']\n",
            "purpose :  [4 7 3 0 1 9 5 6 2 8]\n",
            "savings :  ['A65' 'A61' 'A63' 'A64' 'A62']\n",
            "savings :  [4 0 2 3 1]\n",
            "employmentsince :  ['A75' 'A73' 'A74' 'A71' 'A72']\n",
            "employmentsince :  [4 2 3 0 1]\n",
            "statussex :  ['A93' 'A92' 'A91' 'A94']\n",
            "statussex :  [2 1 0 3]\n",
            "otherdebtors :  ['A101' 'A103' 'A102']\n",
            "otherdebtors :  [0 2 1]\n",
            "property :  ['A121' 'A122' 'A124' 'A123']\n",
            "property :  [0 1 3 2]\n",
            "otherinstallmentplans :  ['A143' 'A141' 'A142']\n",
            "otherinstallmentplans :  [2 0 1]\n",
            "housing :  ['A152' 'A153' 'A151']\n",
            "housing :  [1 2 0]\n",
            "job :  ['A173' 'A172' 'A174' 'A171']\n",
            "job :  [2 1 3 0]\n",
            "telephone :  ['A192' 'A191']\n",
            "telephone :  [1 0]\n",
            "foreignworker :  ['A201' 'A202']\n",
            "foreignworker :  [0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgecTnUUdGl8",
        "colab_type": "code",
        "outputId": "c35bddd0-5ad7-4e0d-d956-8443cc0b35b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "data_clean = pd.concat([numdata_std, lenc], axis = 1)\n",
        "data_clean.head(3)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>existingchecking_A11</th>\n",
              "      <th>existingchecking_A12</th>\n",
              "      <th>existingchecking_A13</th>\n",
              "      <th>existingchecking_A14</th>\n",
              "      <th>credithistory_A30</th>\n",
              "      <th>credithistory_A31</th>\n",
              "      <th>credithistory_A32</th>\n",
              "      <th>credithistory_A33</th>\n",
              "      <th>credithistory_A34</th>\n",
              "      <th>purpose_A40</th>\n",
              "      <th>purpose_A41</th>\n",
              "      <th>purpose_A410</th>\n",
              "      <th>purpose_A42</th>\n",
              "      <th>purpose_A43</th>\n",
              "      <th>purpose_A44</th>\n",
              "      <th>purpose_A45</th>\n",
              "      <th>purpose_A46</th>\n",
              "      <th>purpose_A48</th>\n",
              "      <th>purpose_A49</th>\n",
              "      <th>savings_A61</th>\n",
              "      <th>savings_A62</th>\n",
              "      <th>savings_A63</th>\n",
              "      <th>savings_A64</th>\n",
              "      <th>savings_A65</th>\n",
              "      <th>employmentsince_A71</th>\n",
              "      <th>employmentsince_A72</th>\n",
              "      <th>employmentsince_A73</th>\n",
              "      <th>employmentsince_A74</th>\n",
              "      <th>employmentsince_A75</th>\n",
              "      <th>statussex_A91</th>\n",
              "      <th>statussex_A92</th>\n",
              "      <th>statussex_A93</th>\n",
              "      <th>statussex_A94</th>\n",
              "      <th>otherdebtors_A101</th>\n",
              "      <th>otherdebtors_A102</th>\n",
              "      <th>otherdebtors_A103</th>\n",
              "      <th>property_A121</th>\n",
              "      <th>property_A122</th>\n",
              "      <th>property_A123</th>\n",
              "      <th>property_A124</th>\n",
              "      <th>otherinstallmentplans_A141</th>\n",
              "      <th>otherinstallmentplans_A142</th>\n",
              "      <th>otherinstallmentplans_A143</th>\n",
              "      <th>housing_A151</th>\n",
              "      <th>housing_A152</th>\n",
              "      <th>housing_A153</th>\n",
              "      <th>job_A171</th>\n",
              "      <th>job_A172</th>\n",
              "      <th>job_A173</th>\n",
              "      <th>job_A174</th>\n",
              "      <th>telephone_A191</th>\n",
              "      <th>telephone_A192</th>\n",
              "      <th>foreignworker_A201</th>\n",
              "      <th>foreignworker_A202</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.745131</td>\n",
              "      <td>-1.236478</td>\n",
              "      <td>0.918477</td>\n",
              "      <td>1.046987</td>\n",
              "      <td>2.766456</td>\n",
              "      <td>1.027079</td>\n",
              "      <td>-0.428290</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.949817</td>\n",
              "      <td>2.248194</td>\n",
              "      <td>-0.870183</td>\n",
              "      <td>-0.765977</td>\n",
              "      <td>-1.191404</td>\n",
              "      <td>-0.704926</td>\n",
              "      <td>-0.428290</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.416562</td>\n",
              "      <td>-0.738668</td>\n",
              "      <td>-0.870183</td>\n",
              "      <td>0.140505</td>\n",
              "      <td>1.183312</td>\n",
              "      <td>-0.704926</td>\n",
              "      <td>2.334869</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1  ...  foreignworker_A201  foreignworker_A202\n",
              "0 -0.745131 -1.236478  ...                   1                   0\n",
              "1  0.949817  2.248194  ...                   1                   0\n",
              "2 -0.416562 -0.738668  ...                   1                   0\n",
              "\n",
              "[3 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSLz65TTdK-S",
        "colab_type": "code",
        "outputId": "4d9b9bcb-e35d-43d2-ac48-51617bb3c690",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "data_clean1 = data_clean.rename(columns= { 0:'creditamount', 1: 'duration', 2:'installmentrate', 3:'residencesince', 4:'age', \n",
        "           5:'existingcredits',6: 'peopleliable'})\n",
        "data_clean2 = pd.concat([data_clean1,data['classification']],axis=1)\n",
        "data_clean2.head(3)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>creditamount</th>\n",
              "      <th>duration</th>\n",
              "      <th>installmentrate</th>\n",
              "      <th>residencesince</th>\n",
              "      <th>age</th>\n",
              "      <th>existingcredits</th>\n",
              "      <th>peopleliable</th>\n",
              "      <th>existingchecking_A11</th>\n",
              "      <th>existingchecking_A12</th>\n",
              "      <th>existingchecking_A13</th>\n",
              "      <th>existingchecking_A14</th>\n",
              "      <th>credithistory_A30</th>\n",
              "      <th>credithistory_A31</th>\n",
              "      <th>credithistory_A32</th>\n",
              "      <th>credithistory_A33</th>\n",
              "      <th>credithistory_A34</th>\n",
              "      <th>purpose_A40</th>\n",
              "      <th>purpose_A41</th>\n",
              "      <th>purpose_A410</th>\n",
              "      <th>purpose_A42</th>\n",
              "      <th>purpose_A43</th>\n",
              "      <th>purpose_A44</th>\n",
              "      <th>purpose_A45</th>\n",
              "      <th>purpose_A46</th>\n",
              "      <th>purpose_A48</th>\n",
              "      <th>purpose_A49</th>\n",
              "      <th>savings_A61</th>\n",
              "      <th>savings_A62</th>\n",
              "      <th>savings_A63</th>\n",
              "      <th>savings_A64</th>\n",
              "      <th>savings_A65</th>\n",
              "      <th>employmentsince_A71</th>\n",
              "      <th>employmentsince_A72</th>\n",
              "      <th>employmentsince_A73</th>\n",
              "      <th>employmentsince_A74</th>\n",
              "      <th>employmentsince_A75</th>\n",
              "      <th>statussex_A91</th>\n",
              "      <th>statussex_A92</th>\n",
              "      <th>statussex_A93</th>\n",
              "      <th>statussex_A94</th>\n",
              "      <th>otherdebtors_A101</th>\n",
              "      <th>otherdebtors_A102</th>\n",
              "      <th>otherdebtors_A103</th>\n",
              "      <th>property_A121</th>\n",
              "      <th>property_A122</th>\n",
              "      <th>property_A123</th>\n",
              "      <th>property_A124</th>\n",
              "      <th>otherinstallmentplans_A141</th>\n",
              "      <th>otherinstallmentplans_A142</th>\n",
              "      <th>otherinstallmentplans_A143</th>\n",
              "      <th>housing_A151</th>\n",
              "      <th>housing_A152</th>\n",
              "      <th>housing_A153</th>\n",
              "      <th>job_A171</th>\n",
              "      <th>job_A172</th>\n",
              "      <th>job_A173</th>\n",
              "      <th>job_A174</th>\n",
              "      <th>telephone_A191</th>\n",
              "      <th>telephone_A192</th>\n",
              "      <th>foreignworker_A201</th>\n",
              "      <th>foreignworker_A202</th>\n",
              "      <th>classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.745131</td>\n",
              "      <td>-1.236478</td>\n",
              "      <td>0.918477</td>\n",
              "      <td>1.046987</td>\n",
              "      <td>2.766456</td>\n",
              "      <td>1.027079</td>\n",
              "      <td>-0.428290</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.949817</td>\n",
              "      <td>2.248194</td>\n",
              "      <td>-0.870183</td>\n",
              "      <td>-0.765977</td>\n",
              "      <td>-1.191404</td>\n",
              "      <td>-0.704926</td>\n",
              "      <td>-0.428290</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.416562</td>\n",
              "      <td>-0.738668</td>\n",
              "      <td>-0.870183</td>\n",
              "      <td>0.140505</td>\n",
              "      <td>1.183312</td>\n",
              "      <td>-0.704926</td>\n",
              "      <td>2.334869</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   creditamount  duration  ...  foreignworker_A202  classification\n",
              "0     -0.745131 -1.236478  ...                   0               1\n",
              "1      0.949817  2.248194  ...                   0               0\n",
              "2     -0.416562 -0.738668  ...                   0               1\n",
              "\n",
              "[3 rows x 62 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z15XFT1idqr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unscaled, unnormalized data\n",
        "import random\n",
        "random.seed(42)\n",
        "X_clean = data_clean2.drop('classification', axis=1)\n",
        "y_clean = data_clean2['classification']\n",
        "X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(X_clean,y_clean,test_size=0.2, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxEDE9yP3EPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final=data_clean2.drop([\"existingchecking_A14\",\"credithistory_A30\",\"purpose_A49\",\"savings_A61\",\"employmentsince_A75\",\"statussex_A91\",\"otherdebtors_A103\",\"property_A121\",\"otherinstallmentplans_A143\",\t\"housing_A151\",\"job_A174\",\"telephone_A191\",\"foreignworker_A202\"],axis='columns')\n",
        "# Unscaled, unnormalized data\n",
        "import random\n",
        "random.seed(42)\n",
        "X_clean1 = final.drop('classification', axis=1)\n",
        "y_clean1 = final['classification']\n",
        "X_train_clean1, X_test_clean1, y_train_clean1, y_test_clean1 = train_test_split(X_clean1,y_clean1,test_size=0.2, random_state=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZSEB4qZ3ZKa",
        "colab_type": "code",
        "outputId": "d460ccd3-c124-4775-ed53-f3a47a8f4208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Oversampling\n",
        "# Apply SMOTE\n",
        "sm = SMOTE(ratio='auto')\n",
        "X_train_clean_res, y_train_clean_res = sm.fit_sample(X_train_clean, y_train_clean)\n",
        "\n",
        "# Print number of 'good' credits and 'bad credits, should be fairly balanced now\n",
        "print(\"Before/After clean\")\n",
        "unique, counts = np.unique(y_train_clean, return_counts=True)\n",
        "print(dict(zip(unique, counts)))\n",
        "unique, counts = np.unique(y_train_clean_res, return_counts=True)\n",
        "print(dict(zip(unique, counts)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Before/After clean\n",
            "{0: 241, 1: 559}\n",
            "{0: 559, 1: 559}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQMpkzsf3oip",
        "colab_type": "code",
        "outputId": "f256d141-6530-484b-e175-2f144cfa7c80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Oversampling\n",
        "# Apply SMOTE\n",
        "sm = SMOTE(ratio='auto')\n",
        "X_train_clean_res1, y_train_clean_res1 = sm.fit_sample(X_train_clean1, y_train_clean1)\n",
        "\n",
        "# Print number of 'good' credits and 'bad credits, should be fairly balanced now\n",
        "print(\"Before/After clean\")\n",
        "unique, counts = np.unique(y_train_clean1, return_counts=True)\n",
        "print(dict(zip(unique, counts)))\n",
        "unique, counts = np.unique(y_train_clean_res1, return_counts=True)\n",
        "print(dict(zip(unique, counts)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before/After clean\n",
            "{0: 241, 1: 559}\n",
            "{0: 559, 1: 559}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svc-HLr9d0jn",
        "colab_type": "code",
        "outputId": "0412657a-1686-4198-d880-eec5623b84f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train_clean, y_train_clean)\n",
        "y_pred_lr = classifier.predict(X_test_clean)\n",
        "cm = confusion_matrix(y_test_clean, y_pred_lr)\n",
        "print(cm)\n",
        "print(classification_report(y_test_clean, y_pred_lr))\n",
        "\n",
        "print(\"#############################################\")\n",
        "classifier.fit(X_train_clean1, y_train_clean1)\n",
        "y_pred_lr1 = classifier.predict(X_test_clean1)\n",
        "cm1 = confusion_matrix(y_test_clean1, y_pred_lr1)\n",
        "print(cm1)\n",
        "print(classification_report(y_test_clean1, y_pred_lr1))\n",
        "\n",
        "print(\"#############################################\")\n",
        "classifier.fit(X_train_clean_res, y_train_clean_res)\n",
        "y_pred_lr2 = classifier.predict(X_test_clean)\n",
        "cm2 = confusion_matrix(y_test_clean, y_pred_lr2)\n",
        "print(cm2)\n",
        "print(classification_report(y_test_clean, y_pred_lr2))\n",
        "print(\"#############################################\")\n",
        "\n",
        "classifier.fit(X_train_clean_res1, y_train_clean_res1)\n",
        "y_pred_lr3 = classifier.predict(X_test_clean1)\n",
        "cm3 = confusion_matrix(y_test_clean1, y_pred_lr3)\n",
        "print(cm3)\n",
        "print(classification_report(y_test_clean1, y_pred_lr3))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 25  34]\n",
            " [ 14 127]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.42      0.51        59\n",
            "           1       0.79      0.90      0.84       141\n",
            "\n",
            "    accuracy                           0.76       200\n",
            "   macro avg       0.71      0.66      0.68       200\n",
            "weighted avg       0.75      0.76      0.74       200\n",
            "\n",
            "#############################################\n",
            "[[ 26  33]\n",
            " [ 13 128]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.44      0.53        59\n",
            "           1       0.80      0.91      0.85       141\n",
            "\n",
            "    accuracy                           0.77       200\n",
            "   macro avg       0.73      0.67      0.69       200\n",
            "weighted avg       0.76      0.77      0.75       200\n",
            "\n",
            "#############################################\n",
            "[[ 38  21]\n",
            " [ 33 108]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.64      0.58        59\n",
            "           1       0.84      0.77      0.80       141\n",
            "\n",
            "    accuracy                           0.73       200\n",
            "   macro avg       0.69      0.71      0.69       200\n",
            "weighted avg       0.75      0.73      0.74       200\n",
            "\n",
            "#############################################\n",
            "[[ 37  22]\n",
            " [ 33 108]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.63      0.57        59\n",
            "           1       0.83      0.77      0.80       141\n",
            "\n",
            "    accuracy                           0.73       200\n",
            "   macro avg       0.68      0.70      0.69       200\n",
            "weighted avg       0.74      0.72      0.73       200\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP4qqpvqd3U3",
        "colab_type": "code",
        "outputId": "91e22b46-7004-4959-a9e4-a9ed7454e702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "from sklearn import tree\n",
        "dtree=tree.DecisionTreeClassifier()\n",
        "dtree.fit(X_train_clean,y_train_clean)\n",
        "prediction_dtree=dtree.predict(X_test_clean)\n",
        "cm_dt = confusion_matrix(y_test_clean, prediction_dtree)\n",
        "print(cm_dt)\n",
        "print(classification_report(y_test_clean, prediction_dtree))\n",
        "\n",
        "print(\"#############################################\")\n",
        "dtree.fit(X_train_clean1, y_train_clean1)\n",
        "prediction_dtree1 = dtree.predict(X_test_clean1)\n",
        "cm_dt1 = confusion_matrix(y_test_clean1, prediction_dtree1 )\n",
        "print(cm_dt1)\n",
        "print(classification_report(y_test_clean1, prediction_dtree1 ))\n",
        "\n",
        "print(\"#############################################\")\n",
        "dtree.fit(X_train_clean_res, y_train_clean_res)\n",
        "prediction_dtree2 = dtree.predict(X_test_clean)\n",
        "cm_dt2 = confusion_matrix(y_test_clean, prediction_dtree2)\n",
        "print(cm_dt2)\n",
        "print(classification_report(y_test_clean, prediction_dtree2))\n",
        "\n",
        "print(\"#############################################\")\n",
        "dtree.fit(X_train_clean_res1, y_train_clean_res1)\n",
        "prediction_dtree3 = dtree.predict(X_test_clean1)\n",
        "cm_dt3 = confusion_matrix(y_test_clean1, prediction_dtree3 )\n",
        "print(cm_dt3)\n",
        "print(classification_report(y_test_clean1, prediction_dtree3 ))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 27  32]\n",
            " [ 34 107]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.46      0.45        59\n",
            "           1       0.77      0.76      0.76       141\n",
            "\n",
            "    accuracy                           0.67       200\n",
            "   macro avg       0.61      0.61      0.61       200\n",
            "weighted avg       0.67      0.67      0.67       200\n",
            "\n",
            "#############################################\n",
            "[[ 26  33]\n",
            " [ 35 106]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.44      0.43        59\n",
            "           1       0.76      0.75      0.76       141\n",
            "\n",
            "    accuracy                           0.66       200\n",
            "   macro avg       0.59      0.60      0.60       200\n",
            "weighted avg       0.66      0.66      0.66       200\n",
            "\n",
            "#############################################\n",
            "[[ 26  33]\n",
            " [ 29 112]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.44      0.46        59\n",
            "           1       0.77      0.79      0.78       141\n",
            "\n",
            "    accuracy                           0.69       200\n",
            "   macro avg       0.62      0.62      0.62       200\n",
            "weighted avg       0.68      0.69      0.69       200\n",
            "\n",
            "#############################################\n",
            "[[ 33  26]\n",
            " [ 30 111]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.56      0.54        59\n",
            "           1       0.81      0.79      0.80       141\n",
            "\n",
            "    accuracy                           0.72       200\n",
            "   macro avg       0.67      0.67      0.67       200\n",
            "weighted avg       0.73      0.72      0.72       200\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS4885Kzd9v0",
        "colab_type": "code",
        "outputId": "081814da-52cc-4cd4-9acf-cd12f6929e65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc=RandomForestClassifier(n_estimators=200)\n",
        "rfc.fit(X_train_clean,y_train_clean)\n",
        "prediction_rfc=rfc.predict(X_test_clean)\n",
        "cm_rf = confusion_matrix(y_test_clean, prediction_rfc)\n",
        "print(cm_rf)\n",
        "print(classification_report(y_test_clean, prediction_rfc))\n",
        "\n",
        "print(\"#############################################\")\n",
        "rfc.fit(X_train_clean1,y_train_clean1)\n",
        "prediction_rfc1=rfc.predict(X_test_clean1)\n",
        "cm_rf1 = confusion_matrix(y_test_clean1, prediction_rfc1)\n",
        "print(cm_rf1)\n",
        "print(classification_report(y_test_clean1, prediction_rfc1))\n",
        "\n",
        "print(\"#############################################\")\n",
        "rfc.fit(X_train_clean_res,y_train_clean_res)\n",
        "prediction_rfc2=rfc.predict(X_test_clean)\n",
        "cm_rf2 = confusion_matrix(y_test_clean, prediction_rfc2)\n",
        "print(cm_rf2)\n",
        "print(classification_report(y_test_clean, prediction_rfc2))\n",
        "\n",
        "print(\"#############################################\")\n",
        "rfc.fit(X_train_clean_res1,y_train_clean_res1)\n",
        "prediction_rfc3=rfc.predict(X_test_clean1)\n",
        "cm_rf3 = confusion_matrix(y_test_clean1, prediction_rfc3)\n",
        "print(cm_rf3)\n",
        "print(classification_report(y_test_clean1, prediction_rfc3))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 24  35]\n",
            " [ 10 131]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.41      0.52        59\n",
            "           1       0.79      0.93      0.85       141\n",
            "\n",
            "    accuracy                           0.78       200\n",
            "   macro avg       0.75      0.67      0.68       200\n",
            "weighted avg       0.76      0.78      0.75       200\n",
            "\n",
            "#############################################\n",
            "[[ 20  39]\n",
            " [  7 134]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.34      0.47        59\n",
            "           1       0.77      0.95      0.85       141\n",
            "\n",
            "    accuracy                           0.77       200\n",
            "   macro avg       0.76      0.64      0.66       200\n",
            "weighted avg       0.76      0.77      0.74       200\n",
            "\n",
            "#############################################\n",
            "[[ 24  35]\n",
            " [ 13 128]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.41      0.50        59\n",
            "           1       0.79      0.91      0.84       141\n",
            "\n",
            "    accuracy                           0.76       200\n",
            "   macro avg       0.72      0.66      0.67       200\n",
            "weighted avg       0.74      0.76      0.74       200\n",
            "\n",
            "#############################################\n",
            "[[ 24  35]\n",
            " [ 14 127]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.41      0.49        59\n",
            "           1       0.78      0.90      0.84       141\n",
            "\n",
            "    accuracy                           0.76       200\n",
            "   macro avg       0.71      0.65      0.67       200\n",
            "weighted avg       0.74      0.76      0.74       200\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqK-hnaveDSN",
        "colab_type": "code",
        "outputId": "7caed52a-6169-411a-d87d-8a263d14b64b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        }
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB,  MultinomialNB\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train_clean, y_train_clean)\n",
        "predict_gnb =gnb.predict(X_test_clean)\n",
        "cm_gnb= confusion_matrix(y_test_clean, predict_gnb)\n",
        "print(cm_gnb)\n",
        "print(classification_report(y_test_clean, predict_gnb))\n",
        "\n",
        "print(\"################################################\")\n",
        "gnb.fit(X_train_clean1, y_train_clean1)\n",
        "predict_gnb1 =gnb.predict(X_test_clean1)\n",
        "cm_gnb1= confusion_matrix(y_test_clean1, predict_gnb1)\n",
        "print(cm_gnb1)\n",
        "print(classification_report(y_test_clean1, predict_gnb1))\n",
        "\n",
        "print(\"################################################\")\n",
        "gnb.fit(X_train_clean_res, y_train_clean_res)\n",
        "predict_gnb2 =gnb.predict(X_test_clean)\n",
        "cm_gnb2= confusion_matrix(y_test_clean, predict_gnb2)\n",
        "print(cm_gnb2)\n",
        "print(classification_report(y_test_clean, predict_gnb2))\n",
        "\n",
        "print(\"################################################\")\n",
        "gnb.fit(X_train_clean_res1, y_train_clean_res1)\n",
        "predict_gnb3 =gnb.predict(X_test_clean1)\n",
        "cm_gnb3= confusion_matrix(y_test_clean1, predict_gnb3)\n",
        "print(cm_gnb3)\n",
        "print(classification_report(y_test_clean1, predict_gnb3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 38  21]\n",
            " [ 39 102]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.64      0.56        59\n",
            "           1       0.83      0.72      0.77       141\n",
            "\n",
            "    accuracy                           0.70       200\n",
            "   macro avg       0.66      0.68      0.67       200\n",
            "weighted avg       0.73      0.70      0.71       200\n",
            "\n",
            "################################################\n",
            "[[ 31  28]\n",
            " [ 36 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.53      0.49        59\n",
            "           1       0.79      0.74      0.77       141\n",
            "\n",
            "    accuracy                           0.68       200\n",
            "   macro avg       0.63      0.64      0.63       200\n",
            "weighted avg       0.69      0.68      0.69       200\n",
            "\n",
            "################################################\n",
            "[[41 18]\n",
            " [52 89]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.69      0.54        59\n",
            "           1       0.83      0.63      0.72       141\n",
            "\n",
            "    accuracy                           0.65       200\n",
            "   macro avg       0.64      0.66      0.63       200\n",
            "weighted avg       0.72      0.65      0.67       200\n",
            "\n",
            "################################################\n",
            "[[44 15]\n",
            " [70 71]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.75      0.51        59\n",
            "           1       0.83      0.50      0.63       141\n",
            "\n",
            "    accuracy                           0.57       200\n",
            "   macro avg       0.61      0.62      0.57       200\n",
            "weighted avg       0.70      0.57      0.59       200\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SPBJdpY2EzG",
        "colab_type": "code",
        "outputId": "24ad4020-bf11-4620-d386-e46ab7c9cfab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train_clean, y_train_clean)\n",
        "predict_XGB =model.predict(X_test_clean)\n",
        "cm_XGB= confusion_matrix(y_test_clean, predict_XGB)\n",
        "print(cm_XGB)\n",
        "print(classification_report(y_test_clean, predict_XGB))\n",
        "\n",
        "print(\"################################################\")\n",
        "model.fit(X_train_clean1, y_train_clean1)\n",
        "predict_XGB1 =model.predict(X_test_clean1)\n",
        "cm_XGB1= confusion_matrix(y_test_clean1, predict_XGB1)\n",
        "print(cm_XGB1)\n",
        "print(classification_report(y_test_clean1, predict_XGB1))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 24  35]\n",
            " [ 15 126]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.41      0.49        59\n",
            "           1       0.78      0.89      0.83       141\n",
            "\n",
            "    accuracy                           0.75       200\n",
            "   macro avg       0.70      0.65      0.66       200\n",
            "weighted avg       0.73      0.75      0.73       200\n",
            "\n",
            "################################################\n",
            "[[ 26  33]\n",
            " [ 12 129]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.44      0.54        59\n",
            "           1       0.80      0.91      0.85       141\n",
            "\n",
            "    accuracy                           0.78       200\n",
            "   macro avg       0.74      0.68      0.69       200\n",
            "weighted avg       0.76      0.78      0.76       200\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onpOwO_meS96",
        "colab_type": "code",
        "outputId": "e8dbaae8-55e2-4642-c167-1af72afca93f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import regularizers\n",
        "from keras import optimizers\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "sgd = optimizers.SGD(lr=0.03, decay=0, momentum=0.9, nesterov=False)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(units=50, activation='tanh', input_dim=61,kernel_initializer='glorot_normal', bias_initializer='zeros'))#, kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=1, activation='sigmoid', kernel_initializer='glorot_normal', bias_initializer='zeros'))\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_clean, y_train_clean, validation_data=(X_test_clean, y_test_clean), epochs=50, batch_size=128)\n",
        "[test_loss, test_acc] = model.evaluate(X_test_clean, y_test_clean)\n",
        "print(\"Evaluation result on Test Data : Loss = {}, accuracy = {}\".format(test_loss, test_acc))\n",
        "\n",
        "print(\"####################################################################################################################\")\n",
        "model.fit(X_train_clean_res, y_train_clean_res, validation_data=(X_test_clean, y_test_clean), epochs=50, batch_size=128)\n",
        "[test_loss, test_acc] = model.evaluate(X_test_clean, y_test_clean)\n",
        "print(\"Evaluation result on Test Data : Loss = {}, accuracy = {}\".format(test_loss, test_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0630 05:43:24.090196 140395696600960 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0630 05:43:24.093157 140395696600960 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0630 05:43:24.096210 140395696600960 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "W0630 05:43:24.119151 140395696600960 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0630 05:43:24.129717 140395696600960 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0630 05:43:24.163979 140395696600960 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0630 05:43:24.171960 140395696600960 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0630 05:43:24.180211 140395696600960 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 800 samples, validate on 200 samples\n",
            "Epoch 1/50\n",
            "800/800 [==============================] - 0s 305us/step - loss: 0.7812 - acc: 0.5288 - val_loss: 0.6323 - val_acc: 0.7000\n",
            "Epoch 2/50\n",
            "800/800 [==============================] - 0s 30us/step - loss: 0.6488 - acc: 0.6938 - val_loss: 0.5789 - val_acc: 0.7150\n",
            "Epoch 3/50\n",
            "800/800 [==============================] - 0s 27us/step - loss: 0.5763 - acc: 0.7050 - val_loss: 0.5477 - val_acc: 0.7350\n",
            "Epoch 4/50\n",
            "800/800 [==============================] - 0s 22us/step - loss: 0.5434 - acc: 0.7250 - val_loss: 0.5360 - val_acc: 0.7450\n",
            "Epoch 5/50\n",
            "800/800 [==============================] - 0s 18us/step - loss: 0.5114 - acc: 0.7538 - val_loss: 0.5271 - val_acc: 0.7650\n",
            "Epoch 6/50\n",
            "800/800 [==============================] - 0s 19us/step - loss: 0.5145 - acc: 0.7437 - val_loss: 0.5236 - val_acc: 0.7750\n",
            "Epoch 7/50\n",
            "800/800 [==============================] - 0s 22us/step - loss: 0.5034 - acc: 0.7525 - val_loss: 0.5206 - val_acc: 0.7550\n",
            "Epoch 8/50\n",
            "800/800 [==============================] - 0s 20us/step - loss: 0.4999 - acc: 0.7525 - val_loss: 0.5189 - val_acc: 0.7550\n",
            "Epoch 9/50\n",
            "800/800 [==============================] - 0s 20us/step - loss: 0.4992 - acc: 0.7600 - val_loss: 0.5150 - val_acc: 0.7650\n",
            "Epoch 10/50\n",
            "800/800 [==============================] - 0s 21us/step - loss: 0.4895 - acc: 0.7587 - val_loss: 0.5100 - val_acc: 0.7600\n",
            "Epoch 11/50\n",
            "800/800 [==============================] - 0s 23us/step - loss: 0.4817 - acc: 0.7475 - val_loss: 0.5097 - val_acc: 0.7650\n",
            "Epoch 12/50\n",
            "800/800 [==============================] - 0s 26us/step - loss: 0.4742 - acc: 0.7638 - val_loss: 0.5118 - val_acc: 0.7600\n",
            "Epoch 13/50\n",
            "800/800 [==============================] - 0s 22us/step - loss: 0.4790 - acc: 0.7712 - val_loss: 0.5159 - val_acc: 0.7650\n",
            "Epoch 14/50\n",
            "800/800 [==============================] - 0s 21us/step - loss: 0.4841 - acc: 0.7550 - val_loss: 0.5137 - val_acc: 0.7600\n",
            "Epoch 15/50\n",
            "800/800 [==============================] - 0s 21us/step - loss: 0.4848 - acc: 0.7638 - val_loss: 0.5125 - val_acc: 0.7700\n",
            "Epoch 16/50\n",
            "800/800 [==============================] - 0s 21us/step - loss: 0.4800 - acc: 0.7662 - val_loss: 0.5134 - val_acc: 0.7600\n",
            "Epoch 17/50\n",
            "800/800 [==============================] - 0s 21us/step - loss: 0.4862 - acc: 0.7575 - val_loss: 0.5132 - val_acc: 0.7700\n",
            "Epoch 18/50\n",
            "800/800 [==============================] - 0s 28us/step - loss: 0.4762 - acc: 0.7750 - val_loss: 0.5087 - val_acc: 0.7450\n",
            "Epoch 19/50\n",
            "800/800 [==============================] - 0s 22us/step - loss: 0.4741 - acc: 0.7587 - val_loss: 0.5072 - val_acc: 0.7750\n",
            "Epoch 20/50\n",
            "800/800 [==============================] - 0s 22us/step - loss: 0.4678 - acc: 0.7712 - val_loss: 0.5070 - val_acc: 0.7750\n",
            "Epoch 21/50\n",
            "800/800 [==============================] - 0s 26us/step - loss: 0.4711 - acc: 0.7812 - val_loss: 0.5074 - val_acc: 0.7750\n",
            "Epoch 22/50\n",
            "800/800 [==============================] - 0s 25us/step - loss: 0.4684 - acc: 0.7675 - val_loss: 0.5086 - val_acc: 0.7650\n",
            "Epoch 23/50\n",
            "800/800 [==============================] - 0s 24us/step - loss: 0.4698 - acc: 0.7838 - val_loss: 0.5098 - val_acc: 0.7650\n",
            "Epoch 24/50\n",
            "800/800 [==============================] - 0s 24us/step - loss: 0.4639 - acc: 0.7762 - val_loss: 0.5118 - val_acc: 0.7700\n",
            "Epoch 25/50\n",
            "800/800 [==============================] - 0s 24us/step - loss: 0.4560 - acc: 0.7787 - val_loss: 0.5157 - val_acc: 0.7750\n",
            "Epoch 26/50\n",
            "800/800 [==============================] - 0s 24us/step - loss: 0.4676 - acc: 0.7750 - val_loss: 0.5155 - val_acc: 0.7500\n",
            "Epoch 27/50\n",
            "800/800 [==============================] - 0s 23us/step - loss: 0.4643 - acc: 0.7812 - val_loss: 0.5156 - val_acc: 0.7750\n",
            "Epoch 28/50\n",
            "800/800 [==============================] - 0s 27us/step - loss: 0.4665 - acc: 0.7737 - val_loss: 0.5165 - val_acc: 0.7600\n",
            "Epoch 29/50\n",
            "800/800 [==============================] - 0s 22us/step - loss: 0.4665 - acc: 0.7700 - val_loss: 0.5122 - val_acc: 0.7700\n",
            "Epoch 30/50\n",
            "800/800 [==============================] - 0s 21us/step - loss: 0.4671 - acc: 0.7750 - val_loss: 0.5098 - val_acc: 0.7550\n",
            "Epoch 31/50\n",
            "800/800 [==============================] - 0s 22us/step - loss: 0.4741 - acc: 0.7625 - val_loss: 0.5090 - val_acc: 0.7550\n",
            "Epoch 32/50\n",
            "800/800 [==============================] - 0s 22us/step - loss: 0.4594 - acc: 0.7825 - val_loss: 0.5105 - val_acc: 0.7550\n",
            "Epoch 33/50\n",
            "800/800 [==============================] - 0s 21us/step - loss: 0.4751 - acc: 0.7600 - val_loss: 0.5070 - val_acc: 0.7650\n",
            "Epoch 34/50\n",
            "800/800 [==============================] - 0s 29us/step - loss: 0.4687 - acc: 0.7800 - val_loss: 0.5060 - val_acc: 0.7600\n",
            "Epoch 35/50\n",
            "800/800 [==============================] - 0s 23us/step - loss: 0.4670 - acc: 0.7712 - val_loss: 0.5073 - val_acc: 0.7600\n",
            "Epoch 36/50\n",
            "800/800 [==============================] - 0s 22us/step - loss: 0.4551 - acc: 0.7775 - val_loss: 0.5096 - val_acc: 0.7500\n",
            "Epoch 37/50\n",
            "800/800 [==============================] - 0s 23us/step - loss: 0.4657 - acc: 0.7688 - val_loss: 0.5101 - val_acc: 0.7550\n",
            "Epoch 38/50\n",
            "800/800 [==============================] - 0s 20us/step - loss: 0.4629 - acc: 0.7762 - val_loss: 0.5148 - val_acc: 0.7650\n",
            "Epoch 39/50\n",
            "800/800 [==============================] - 0s 24us/step - loss: 0.4501 - acc: 0.7863 - val_loss: 0.5121 - val_acc: 0.7700\n",
            "Epoch 40/50\n",
            "800/800 [==============================] - 0s 24us/step - loss: 0.4673 - acc: 0.7812 - val_loss: 0.5111 - val_acc: 0.7550\n",
            "Epoch 41/50\n",
            "800/800 [==============================] - 0s 24us/step - loss: 0.4448 - acc: 0.7913 - val_loss: 0.5092 - val_acc: 0.7600\n",
            "Epoch 42/50\n",
            "800/800 [==============================] - 0s 23us/step - loss: 0.4648 - acc: 0.7762 - val_loss: 0.5094 - val_acc: 0.7750\n",
            "Epoch 43/50\n",
            "800/800 [==============================] - 0s 21us/step - loss: 0.4608 - acc: 0.7750 - val_loss: 0.5072 - val_acc: 0.7750\n",
            "Epoch 44/50\n",
            "800/800 [==============================] - 0s 23us/step - loss: 0.4650 - acc: 0.7737 - val_loss: 0.5089 - val_acc: 0.7750\n",
            "Epoch 45/50\n",
            "800/800 [==============================] - 0s 26us/step - loss: 0.4460 - acc: 0.7987 - val_loss: 0.5089 - val_acc: 0.7550\n",
            "Epoch 46/50\n",
            "800/800 [==============================] - 0s 31us/step - loss: 0.4641 - acc: 0.7800 - val_loss: 0.5095 - val_acc: 0.7750\n",
            "Epoch 47/50\n",
            "800/800 [==============================] - 0s 22us/step - loss: 0.4588 - acc: 0.7812 - val_loss: 0.5123 - val_acc: 0.7700\n",
            "Epoch 48/50\n",
            "800/800 [==============================] - 0s 20us/step - loss: 0.4535 - acc: 0.7900 - val_loss: 0.5120 - val_acc: 0.7700\n",
            "Epoch 49/50\n",
            "800/800 [==============================] - 0s 21us/step - loss: 0.4682 - acc: 0.7750 - val_loss: 0.5131 - val_acc: 0.7650\n",
            "Epoch 50/50\n",
            "800/800 [==============================] - 0s 21us/step - loss: 0.4626 - acc: 0.7863 - val_loss: 0.5118 - val_acc: 0.7750\n",
            "200/200 [==============================] - 0s 50us/step\n",
            "Evaluation result on Test Data : Loss = 0.5117677354812622, accuracy = 0.775\n",
            "####################################################################################################################\n",
            "Train on 1118 samples, validate on 200 samples\n",
            "Epoch 1/50\n",
            "1118/1118 [==============================] - 0s 19us/step - loss: 0.5211 - acc: 0.7370 - val_loss: 0.6057 - val_acc: 0.6700\n",
            "Epoch 2/50\n",
            "1118/1118 [==============================] - 0s 21us/step - loss: 0.5060 - acc: 0.7531 - val_loss: 0.5616 - val_acc: 0.7050\n",
            "Epoch 3/50\n",
            "1118/1118 [==============================] - 0s 18us/step - loss: 0.4890 - acc: 0.7630 - val_loss: 0.5335 - val_acc: 0.7200\n",
            "Epoch 4/50\n",
            "1118/1118 [==============================] - 0s 18us/step - loss: 0.5001 - acc: 0.7522 - val_loss: 0.5696 - val_acc: 0.7000\n",
            "Epoch 5/50\n",
            "1118/1118 [==============================] - 0s 19us/step - loss: 0.4877 - acc: 0.7531 - val_loss: 0.5510 - val_acc: 0.7300\n",
            "Epoch 6/50\n",
            "1118/1118 [==============================] - 0s 19us/step - loss: 0.4901 - acc: 0.7674 - val_loss: 0.5459 - val_acc: 0.7300\n",
            "Epoch 7/50\n",
            "1118/1118 [==============================] - 0s 20us/step - loss: 0.4783 - acc: 0.7648 - val_loss: 0.5561 - val_acc: 0.7250\n",
            "Epoch 8/50\n",
            "1118/1118 [==============================] - 0s 22us/step - loss: 0.4957 - acc: 0.7621 - val_loss: 0.5547 - val_acc: 0.7300\n",
            "Epoch 9/50\n",
            "1118/1118 [==============================] - 0s 17us/step - loss: 0.4966 - acc: 0.7674 - val_loss: 0.5433 - val_acc: 0.7250\n",
            "Epoch 10/50\n",
            "1118/1118 [==============================] - 0s 17us/step - loss: 0.4878 - acc: 0.7603 - val_loss: 0.5472 - val_acc: 0.7200\n",
            "Epoch 11/50\n",
            "1118/1118 [==============================] - 0s 17us/step - loss: 0.4837 - acc: 0.7773 - val_loss: 0.5409 - val_acc: 0.7300\n",
            "Epoch 12/50\n",
            "1118/1118 [==============================] - 0s 17us/step - loss: 0.4862 - acc: 0.7728 - val_loss: 0.5613 - val_acc: 0.7000\n",
            "Epoch 13/50\n",
            "1118/1118 [==============================] - 0s 17us/step - loss: 0.4894 - acc: 0.7648 - val_loss: 0.5469 - val_acc: 0.7250\n",
            "Epoch 14/50\n",
            "1118/1118 [==============================] - 0s 17us/step - loss: 0.4894 - acc: 0.7621 - val_loss: 0.5691 - val_acc: 0.7050\n",
            "Epoch 15/50\n",
            "1118/1118 [==============================] - 0s 21us/step - loss: 0.4874 - acc: 0.7728 - val_loss: 0.5474 - val_acc: 0.7300\n",
            "Epoch 16/50\n",
            "1118/1118 [==============================] - 0s 20us/step - loss: 0.4850 - acc: 0.7683 - val_loss: 0.5473 - val_acc: 0.7350\n",
            "Epoch 17/50\n",
            "1118/1118 [==============================] - 0s 25us/step - loss: 0.4814 - acc: 0.7782 - val_loss: 0.5672 - val_acc: 0.7050\n",
            "Epoch 18/50\n",
            "1118/1118 [==============================] - 0s 19us/step - loss: 0.4799 - acc: 0.7746 - val_loss: 0.5396 - val_acc: 0.7400\n",
            "Epoch 19/50\n",
            "1118/1118 [==============================] - 0s 20us/step - loss: 0.4824 - acc: 0.7630 - val_loss: 0.5671 - val_acc: 0.7100\n",
            "Epoch 20/50\n",
            "1118/1118 [==============================] - 0s 19us/step - loss: 0.4879 - acc: 0.7764 - val_loss: 0.5449 - val_acc: 0.7300\n",
            "Epoch 21/50\n",
            "1118/1118 [==============================] - 0s 18us/step - loss: 0.4880 - acc: 0.7665 - val_loss: 0.5484 - val_acc: 0.7250\n",
            "Epoch 22/50\n",
            "1118/1118 [==============================] - 0s 18us/step - loss: 0.4934 - acc: 0.7683 - val_loss: 0.5614 - val_acc: 0.7200\n",
            "Epoch 23/50\n",
            "1118/1118 [==============================] - 0s 18us/step - loss: 0.4871 - acc: 0.7683 - val_loss: 0.5535 - val_acc: 0.7200\n",
            "Epoch 24/50\n",
            "1118/1118 [==============================] - 0s 19us/step - loss: 0.4874 - acc: 0.7791 - val_loss: 0.5511 - val_acc: 0.7150\n",
            "Epoch 25/50\n",
            "1118/1118 [==============================] - 0s 19us/step - loss: 0.4805 - acc: 0.7764 - val_loss: 0.5506 - val_acc: 0.7250\n",
            "Epoch 26/50\n",
            "1118/1118 [==============================] - 0s 18us/step - loss: 0.4868 - acc: 0.7648 - val_loss: 0.5613 - val_acc: 0.7200\n",
            "Epoch 27/50\n",
            "1118/1118 [==============================] - 0s 20us/step - loss: 0.4753 - acc: 0.7737 - val_loss: 0.5509 - val_acc: 0.7250\n",
            "Epoch 28/50\n",
            "1118/1118 [==============================] - 0s 17us/step - loss: 0.4694 - acc: 0.7889 - val_loss: 0.5488 - val_acc: 0.7250\n",
            "Epoch 29/50\n",
            "1118/1118 [==============================] - 0s 22us/step - loss: 0.4768 - acc: 0.7657 - val_loss: 0.5546 - val_acc: 0.7250\n",
            "Epoch 30/50\n",
            "1118/1118 [==============================] - 0s 19us/step - loss: 0.4725 - acc: 0.7683 - val_loss: 0.5550 - val_acc: 0.7350\n",
            "Epoch 31/50\n",
            "1118/1118 [==============================] - 0s 17us/step - loss: 0.4835 - acc: 0.7746 - val_loss: 0.5498 - val_acc: 0.7300\n",
            "Epoch 32/50\n",
            "1118/1118 [==============================] - 0s 20us/step - loss: 0.4743 - acc: 0.7844 - val_loss: 0.5384 - val_acc: 0.7400\n",
            "Epoch 33/50\n",
            "1118/1118 [==============================] - 0s 19us/step - loss: 0.4777 - acc: 0.7755 - val_loss: 0.5597 - val_acc: 0.7200\n",
            "Epoch 34/50\n",
            "1118/1118 [==============================] - 0s 21us/step - loss: 0.4772 - acc: 0.7692 - val_loss: 0.5597 - val_acc: 0.7150\n",
            "Epoch 35/50\n",
            "1118/1118 [==============================] - 0s 18us/step - loss: 0.4784 - acc: 0.7657 - val_loss: 0.5493 - val_acc: 0.7350\n",
            "Epoch 36/50\n",
            "1118/1118 [==============================] - 0s 20us/step - loss: 0.4630 - acc: 0.7755 - val_loss: 0.5729 - val_acc: 0.7150\n",
            "Epoch 37/50\n",
            "1118/1118 [==============================] - 0s 19us/step - loss: 0.4776 - acc: 0.7791 - val_loss: 0.5609 - val_acc: 0.7150\n",
            "Epoch 38/50\n",
            "1118/1118 [==============================] - 0s 17us/step - loss: 0.4735 - acc: 0.7818 - val_loss: 0.5443 - val_acc: 0.7300\n",
            "Epoch 39/50\n",
            "1118/1118 [==============================] - 0s 19us/step - loss: 0.4627 - acc: 0.7737 - val_loss: 0.5394 - val_acc: 0.7500\n",
            "Epoch 40/50\n",
            "1118/1118 [==============================] - 0s 20us/step - loss: 0.4664 - acc: 0.7710 - val_loss: 0.5584 - val_acc: 0.7200\n",
            "Epoch 41/50\n",
            "1118/1118 [==============================] - 0s 17us/step - loss: 0.4757 - acc: 0.7710 - val_loss: 0.5326 - val_acc: 0.7400\n",
            "Epoch 42/50\n",
            "1118/1118 [==============================] - 0s 19us/step - loss: 0.4735 - acc: 0.7665 - val_loss: 0.5623 - val_acc: 0.7200\n",
            "Epoch 43/50\n",
            "1118/1118 [==============================] - 0s 19us/step - loss: 0.4658 - acc: 0.7826 - val_loss: 0.5528 - val_acc: 0.7300\n",
            "Epoch 44/50\n",
            "1118/1118 [==============================] - 0s 16us/step - loss: 0.4693 - acc: 0.7782 - val_loss: 0.5486 - val_acc: 0.7250\n",
            "Epoch 45/50\n",
            "1118/1118 [==============================] - 0s 19us/step - loss: 0.4682 - acc: 0.7737 - val_loss: 0.5613 - val_acc: 0.7100\n",
            "Epoch 46/50\n",
            "1118/1118 [==============================] - 0s 20us/step - loss: 0.4706 - acc: 0.7818 - val_loss: 0.5494 - val_acc: 0.7250\n",
            "Epoch 47/50\n",
            "1118/1118 [==============================] - 0s 22us/step - loss: 0.4726 - acc: 0.7835 - val_loss: 0.5521 - val_acc: 0.7200\n",
            "Epoch 48/50\n",
            "1118/1118 [==============================] - 0s 17us/step - loss: 0.4736 - acc: 0.7791 - val_loss: 0.5580 - val_acc: 0.7300\n",
            "Epoch 49/50\n",
            "1118/1118 [==============================] - 0s 19us/step - loss: 0.4709 - acc: 0.7764 - val_loss: 0.5443 - val_acc: 0.7350\n",
            "Epoch 50/50\n",
            "1118/1118 [==============================] - 0s 17us/step - loss: 0.4668 - acc: 0.7701 - val_loss: 0.5383 - val_acc: 0.7400\n",
            "200/200 [==============================] - 0s 46us/step\n",
            "Evaluation result on Test Data : Loss = 0.5383007049560546, accuracy = 0.74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jmc7CR1F6Mh",
        "colab_type": "code",
        "outputId": "b8e1bcc6-4fde-47c5-8768-0959586da3b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "rf = RandomForestClassifier(n_estimators= 50, max_depth= 20, n_jobs= -1)\n",
        "rf_model = rf.fit(X_train_clean,y_train_clean)\n",
        "sorted(zip(rf.feature_importances_,X_train_clean.columns), reverse = True)[0:15]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.09934268729925991, 'creditamount'),\n",
              " (0.08183614749566613, 'age'),\n",
              " (0.07558309569471236, 'duration'),\n",
              " (0.0432992557826157, 'existingchecking_A11'),\n",
              " (0.03977736932931203, 'installmentrate'),\n",
              " (0.0356243230115727, 'existingchecking_A14'),\n",
              " (0.031840463443462565, 'residencesince'),\n",
              " (0.0286497312092421, 'credithistory_A34'),\n",
              " (0.021184391606679225, 'existingchecking_A12'),\n",
              " (0.01974605218469066, 'savings_A61'),\n",
              " (0.018135503979555954, 'credithistory_A30'),\n",
              " (0.01802240458872968, 'otherinstallmentplans_A143'),\n",
              " (0.01763134193610312, 'existingcredits'),\n",
              " (0.01719543614833961, 'employmentsince_A73'),\n",
              " (0.017164585167830565, 'purpose_A40')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N64pw4pVG4YT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_clean3 =data_clean1.drop([\"peopleliable\"\t,\"existingchecking_A12\",\"existingchecking_A13\",\"credithistory_A30\",\"credithistory_A31\",\"credithistory_A32\",\"credithistory_A33\",\"purpose_A41\",\"purpose_A410\",\"purpose_A42\",\"purpose_A43\",\"purpose_A44\",\"purpose_A45\",\"purpose_A46\",\"purpose_A48\",\"purpose_A49\",\"savings_A62\",\"savings_A63\",\"savings_A64\",\"savings_A65\",\"employmentsince_A71\",\"employmentsince_A74\",\"employmentsince_A75\",\"statussex_A91\",\"statussex_A92\",\"statussex_A94\",\"otherdebtors_A101\",\"otherdebtors_A102\",\"otherdebtors_A103\",\"property_A122\",\"property_A123\",\"property_A124\",\"otherinstallmentplans_A141\",\"otherinstallmentplans_A142\",\"otherinstallmentplans_A143\",\"housing_A151\",\"housing_A152\",\"housing_A153\",\"job_A171\",\t\"job_A172\",\t\"job_A173\",\t\"job_A174\",\"telephone_A191\"\t,\"telephone_A192\",\t\"foreignworker_A201\",\"foreignworker_A202\"], axis=1)\n",
        "data_clean4 = pd.concat([data_clean3,data['classification']],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp6gvvHYP7g7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unscaled, unnormalized data\n",
        "import random\n",
        "random.seed(42)\n",
        "X_clean3 = data_clean4.drop('classification', axis=1)\n",
        "y_clean3 = data_clean4['classification']\n",
        "X_train_clean5, X_test_clean5, y_train_clean5, y_test_clean5 = train_test_split(X_clean3,y_clean3,test_size=0.2, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFMe9unAQDsG",
        "colab_type": "code",
        "outputId": "4ff163c1-7488-48e2-e9b4-cdb0fe3546c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Oversampling\n",
        "# Apply SMOTE\n",
        "sm = SMOTE(ratio='auto')\n",
        "X_train_clean_res5, y_train_clean_res5 = sm.fit_sample(X_train_clean5, y_train_clean5)\n",
        "\n",
        "# Print number of 'good' credits and 'bad credits, should be fairly balanced now\n",
        "print(\"Before/After clean\")\n",
        "unique, counts = np.unique(y_train_clean5, return_counts=True)\n",
        "print(dict(zip(unique, counts)))\n",
        "unique, counts = np.unique(y_train_clean_res5, return_counts=True)\n",
        "print(dict(zip(unique, counts)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before/After clean\n",
            "{0: 241, 1: 559}\n",
            "{0: 559, 1: 559}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be30yWSeQn4R",
        "colab_type": "code",
        "outputId": "bc2a7bf2-1547-4187-8c58-6e74a846012b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train_clean5, y_train_clean5)\n",
        "y_pred_lr5 = classifier.predict(X_test_clean5)\n",
        "cm5 = confusion_matrix(y_test_clean5, y_pred_lr5)\n",
        "print(cm5)\n",
        "print(classification_report(y_test_clean5, y_pred_lr5))\n",
        "\n",
        "\n",
        "print(\"#############################################\")\n",
        "classifier.fit(X_train_clean_res5, y_train_clean_res5)\n",
        "y_pred_lr6 = classifier.predict(X_test_clean5)\n",
        "cm6 = confusion_matrix(y_test_clean5, y_pred_lr6)\n",
        "print(cm6)\n",
        "print(classification_report(y_test_clean5, y_pred_lr6))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 26  33]\n",
            " [ 16 125]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.44      0.51        59\n",
            "           1       0.79      0.89      0.84       141\n",
            "\n",
            "    accuracy                           0.76       200\n",
            "   macro avg       0.71      0.66      0.68       200\n",
            "weighted avg       0.74      0.76      0.74       200\n",
            "\n",
            "#############################################\n",
            "[[ 38  21]\n",
            " [ 37 104]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.64      0.57        59\n",
            "           1       0.83      0.74      0.78       141\n",
            "\n",
            "    accuracy                           0.71       200\n",
            "   macro avg       0.67      0.69      0.67       200\n",
            "weighted avg       0.74      0.71      0.72       200\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj211Tl0Rpqz",
        "colab_type": "code",
        "outputId": "80462ed3-f5d9-485c-e6c6-62691405f3c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "from sklearn import tree\n",
        "dtree=tree.DecisionTreeClassifier()\n",
        "dtree.fit(X_train_clean5,y_train_clean5)\n",
        "prediction_dtree5=dtree.predict(X_test_clean5)\n",
        "cm_dt5 = confusion_matrix(y_test_clean5, prediction_dtree5)\n",
        "print(cm_dt5)\n",
        "print(classification_report(y_test_clean5, prediction_dtree5))\n",
        "\n",
        "\n",
        "print(\"#############################################\")\n",
        "dtree.fit(X_train_clean_res5,y_train_clean_res5)\n",
        "prediction_dtree6=dtree.predict(X_test_clean5)\n",
        "cm_dt6 = confusion_matrix(y_test_clean5, prediction_dtree6)\n",
        "print(cm_dt6)\n",
        "print(classification_report(y_test_clean5, prediction_dtree6))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 28  31]\n",
            " [ 32 109]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.47      0.47        59\n",
            "           1       0.78      0.77      0.78       141\n",
            "\n",
            "    accuracy                           0.69       200\n",
            "   macro avg       0.62      0.62      0.62       200\n",
            "weighted avg       0.69      0.69      0.69       200\n",
            "\n",
            "#############################################\n",
            "[[ 24  35]\n",
            " [ 28 113]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.41      0.43        59\n",
            "           1       0.76      0.80      0.78       141\n",
            "\n",
            "    accuracy                           0.69       200\n",
            "   macro avg       0.61      0.60      0.61       200\n",
            "weighted avg       0.67      0.69      0.68       200\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI2Vh0X2SEVP",
        "colab_type": "code",
        "outputId": "6b14d668-c2e5-44a7-e99e-c152f319c3f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc=RandomForestClassifier(n_estimators=200)\n",
        "rfc.fit(X_train_clean5,y_train_clean5)\n",
        "prediction_rfc5=rfc.predict(X_test_clean5)\n",
        "cm_rf5 = confusion_matrix(y_test_clean5, prediction_rfc5)\n",
        "print(cm_rf5)\n",
        "print(classification_report(y_test_clean5, prediction_rfc5))\n",
        "\n",
        "\n",
        "print(\"#############################################################\")\n",
        "rfc.fit(X_train_clean_res5,y_train_clean_res5)\n",
        "prediction_rfc5=rfc.predict(X_test_clean5)\n",
        "cm_rf5 = confusion_matrix(y_test_clean5, prediction_rfc5)\n",
        "print(cm_rf5)\n",
        "print(classification_report(y_test_clean5, prediction_rfc5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 21  38]\n",
            " [ 14 127]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.36      0.45        59\n",
            "           1       0.77      0.90      0.83       141\n",
            "\n",
            "    accuracy                           0.74       200\n",
            "   macro avg       0.68      0.63      0.64       200\n",
            "weighted avg       0.72      0.74      0.72       200\n",
            "\n",
            "#############################################################\n",
            "[[ 24  35]\n",
            " [ 20 121]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.41      0.47        59\n",
            "           1       0.78      0.86      0.81       141\n",
            "\n",
            "    accuracy                           0.73       200\n",
            "   macro avg       0.66      0.63      0.64       200\n",
            "weighted avg       0.71      0.72      0.71       200\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3sV3gLVSsgL",
        "colab_type": "code",
        "outputId": "67d2e4c3-fbb7-4690-9136-3cc88b822961",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train_clean5, y_train_clean5)\n",
        "predict_XGB5 =model.predict(X_test_clean5)\n",
        "cm_XGB5= confusion_matrix(y_test_clean5, predict_XGB5)\n",
        "print(cm_XGB5)\n",
        "print(classification_report(y_test_clean5, predict_XGB5))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 23  36]\n",
            " [ 15 126]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.39      0.47        59\n",
            "           1       0.78      0.89      0.83       141\n",
            "\n",
            "    accuracy                           0.74       200\n",
            "   macro avg       0.69      0.64      0.65       200\n",
            "weighted avg       0.73      0.74      0.73       200\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwkxKgcO5ULh",
        "colab_type": "code",
        "outputId": "946829de-9b26-4c3c-eebe-6f40131c01a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "auc = roc_auc_score(y_test_clean, prediction_rfc)\n",
        "print('AUC: %.3f' % auc)\n",
        "# calculate roc curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test_clean, prediction_rfc)\n",
        "# plot no skill\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "# plot the roc curve for the model\n",
        "plt.plot(fpr, tpr, marker='.')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "\n",
        "# show the plot\n",
        "plt.show()\n",
        "\n",
        "print(\"###############################################\")\n",
        "auc = roc_auc_score(y_test_clean1, prediction_rfc1)\n",
        "print('AUC: %.3f' % auc)\n",
        "# calculate roc curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test_clean1, prediction_rfc1)\n",
        "# plot no skill\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "# plot the roc curve for the model\n",
        "plt.plot(fpr, tpr, marker='.')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "\n",
        "# show the plot\n",
        "plt.show()\n",
        "\n",
        "print(\"###############################################\")\n",
        "auc = roc_auc_score(y_test_clean, prediction_rfc2)\n",
        "print('AUC: %.3f' % auc)\n",
        "# calculate roc curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test_clean, prediction_rfc2)\n",
        "# plot no skill\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "# plot the roc curve for the model\n",
        "plt.plot(fpr, tpr, marker='.')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "\n",
        "# show the plot\n",
        "plt.show()\n",
        "\n",
        "print(\"###############################################\")      \n",
        "auc = roc_auc_score(y_test_clean1, prediction_rfc3)\n",
        "print('AUC: %.3f' % auc)\n",
        "# calculate roc curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test_clean1, prediction_rfc3)\n",
        "# plot no skill\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "# plot the roc curve for the model\n",
        "plt.plot(fpr, tpr, marker='.')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "\n",
        "# show the plot\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.639\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhYKIiORTKIiISD6FgoiI5Pt/CNNBTIUMJsoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "###############################################\n",
            "AUC: 0.640\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "###############################################\n",
            "AUC: 0.651\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niBRRKIiISJH/B90YQ/ZumI0UAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "###############################################\n",
            "AUC: 0.666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKRRERCSXQkFERHIpFEREJNf/AwFnOGqVBZOZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpJJHURDY2Vn",
        "colab_type": "code",
        "outputId": "d12f6cc4-ed96-4a2a-ea8b-73598b6e5303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "rfc.fit(X_train_clean1,y_train_clean1)\n",
        "prediction_rfc1=rfc.predict(X_test_clean1)\n",
        "cm_rf1 = confusion_matrix()\n",
        "print(cm_rf1)\n",
        "print(classification_report(y_test_clean1, prediction_rfc1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 21  38]\n",
            " [ 12 129]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.36      0.46        59\n",
            "           1       0.77      0.91      0.84       141\n",
            "\n",
            "    accuracy                           0.75       200\n",
            "   macro avg       0.70      0.64      0.65       200\n",
            "weighted avg       0.73      0.75      0.73       200\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sifWL5wpyQ_l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fe9cb772-fe63-4831-fe3e-8a76b8629a59"
      },
      "source": [
        "df=pd.DataFrame(prediction_rfc1, columns=['y_predict'])\n",
        "df"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows  1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     y_predict\n",
              "0            1\n",
              "1            0\n",
              "2            1\n",
              "3            0\n",
              "4            0\n",
              "5            0\n",
              "6            1\n",
              "7            1\n",
              "8            1\n",
              "9            1\n",
              "10           0\n",
              "11           1\n",
              "12           1\n",
              "13           1\n",
              "14           1\n",
              "15           1\n",
              "16           1\n",
              "17           1\n",
              "18           1\n",
              "19           0\n",
              "20           1\n",
              "21           1\n",
              "22           1\n",
              "23           1\n",
              "24           1\n",
              "25           1\n",
              "26           0\n",
              "27           1\n",
              "28           1\n",
              "29           0\n",
              "..         ...\n",
              "170          1\n",
              "171          1\n",
              "172          1\n",
              "173          1\n",
              "174          1\n",
              "175          0\n",
              "176          1\n",
              "177          1\n",
              "178          1\n",
              "179          1\n",
              "180          1\n",
              "181          1\n",
              "182          0\n",
              "183          1\n",
              "184          1\n",
              "185          1\n",
              "186          1\n",
              "187          1\n",
              "188          1\n",
              "189          1\n",
              "190          1\n",
              "191          1\n",
              "192          1\n",
              "193          1\n",
              "194          1\n",
              "195          1\n",
              "196          1\n",
              "197          1\n",
              "198          1\n",
              "199          1\n",
              "\n",
              "[200 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFeyOlTzIc_b",
        "colab_type": "code",
        "outputId": "6f04348f-e865-4988-bfbf-4af4d3b527a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "X_test_clean1.reset_index(inplace=True)\n",
        "X_test_clean1.drop(['index'],axis=1,inplace=True)\n",
        "y_test_clean1=y_test_clean1.reset_index(drop=True)\n",
        "output_1 = X_test_clean1.join(df,how='outer')\n",
        "final = output_1.join(y_test_clean1,how='outer')\n",
        "final.head(3)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  errors=errors)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>creditamount</th>\n",
              "      <th>duration</th>\n",
              "      <th>installmentrate</th>\n",
              "      <th>residencesince</th>\n",
              "      <th>age</th>\n",
              "      <th>existingcredits</th>\n",
              "      <th>peopleliable</th>\n",
              "      <th>existingchecking_A11</th>\n",
              "      <th>existingchecking_A12</th>\n",
              "      <th>existingchecking_A13</th>\n",
              "      <th>credithistory_A31</th>\n",
              "      <th>credithistory_A32</th>\n",
              "      <th>credithistory_A33</th>\n",
              "      <th>credithistory_A34</th>\n",
              "      <th>purpose_A40</th>\n",
              "      <th>purpose_A41</th>\n",
              "      <th>purpose_A410</th>\n",
              "      <th>purpose_A42</th>\n",
              "      <th>purpose_A43</th>\n",
              "      <th>purpose_A44</th>\n",
              "      <th>purpose_A45</th>\n",
              "      <th>purpose_A46</th>\n",
              "      <th>purpose_A48</th>\n",
              "      <th>savings_A62</th>\n",
              "      <th>savings_A63</th>\n",
              "      <th>savings_A64</th>\n",
              "      <th>savings_A65</th>\n",
              "      <th>employmentsince_A71</th>\n",
              "      <th>employmentsince_A72</th>\n",
              "      <th>employmentsince_A73</th>\n",
              "      <th>employmentsince_A74</th>\n",
              "      <th>statussex_A92</th>\n",
              "      <th>statussex_A93</th>\n",
              "      <th>statussex_A94</th>\n",
              "      <th>otherdebtors_A101</th>\n",
              "      <th>otherdebtors_A102</th>\n",
              "      <th>property_A122</th>\n",
              "      <th>property_A123</th>\n",
              "      <th>property_A124</th>\n",
              "      <th>otherinstallmentplans_A141</th>\n",
              "      <th>otherinstallmentplans_A142</th>\n",
              "      <th>housing_A152</th>\n",
              "      <th>housing_A153</th>\n",
              "      <th>job_A171</th>\n",
              "      <th>job_A172</th>\n",
              "      <th>job_A173</th>\n",
              "      <th>telephone_A192</th>\n",
              "      <th>foreignworker_A201</th>\n",
              "      <th>y_predict</th>\n",
              "      <th>classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.268461</td>\n",
              "      <td>-0.489762</td>\n",
              "      <td>-1.764514</td>\n",
              "      <td>-0.765977</td>\n",
              "      <td>-0.135974</td>\n",
              "      <td>-0.704926</td>\n",
              "      <td>2.334869</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.460933</td>\n",
              "      <td>1.252574</td>\n",
              "      <td>-0.870183</td>\n",
              "      <td>0.140505</td>\n",
              "      <td>0.655598</td>\n",
              "      <td>-0.704926</td>\n",
              "      <td>-0.428290</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.181566</td>\n",
              "      <td>-0.738668</td>\n",
              "      <td>-0.870183</td>\n",
              "      <td>1.046987</td>\n",
              "      <td>-0.135974</td>\n",
              "      <td>1.027079</td>\n",
              "      <td>-0.428290</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   creditamount  duration  ...  y_predict  classification\n",
              "0      1.268461 -0.489762  ...          1               0\n",
              "1      4.460933  1.252574  ...          0               1\n",
              "2     -0.181566 -0.738668  ...          1               1\n",
              "\n",
              "[3 rows x 50 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3ta2uJfMFgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "final.to_csv('comparison.csv')\n",
        "files.download('comparison.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}